{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"biorxiv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affiliatin_nums: Replace NAs with 1, for single affiliation.\n",
    "#Affiliation_nums: Split into list\n",
    "df.affiliation_nums = df.affiliation_nums.fillna('1')\n",
    "df.affiliation_nums = df.affiliation_nums.apply(str.split,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affiliation_text: Replace NAs with empty string\n",
    "#Run clean_affiliation, to \n",
    "def clean_affiliation(x):\n",
    "    x = x.split(';')\n",
    "    for i in range(len(x)):\n",
    "        x[i] = re.sub('(\\\\n)(\\\\t)+','',x[i])\n",
    "        x[i] = x[i].strip()\n",
    "        x[i] = re.sub('^,+','',x[i])\n",
    "        x[i] = x[i].strip()\n",
    "    return(x)\n",
    "df.affiliation_text = df.affiliation_text.fillna('')\n",
    "df.affiliation_text = df.affiliation_text.apply(clean_affiliation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning number of downloads\n",
    "def clean_downloads(x):\n",
    "    x = x.split(',')\n",
    "    x = map(lambda y: re.sub('<tr class=\"odd\">','',y),x)\n",
    "    x = map(lambda y: re.sub('<tr class=\"even\">','',y),x)\n",
    "    x = map(lambda y: re.sub(' </tr>','',y),x)\n",
    "    x = list(map(lambda y: y.split('</td>'),x))\n",
    "    for i in range(len(x)):\n",
    "        x[i] = list(map(lambda y: re.sub('^<td>','',y),x[i]))\n",
    "    return x\n",
    "df.downloads = df.downloads.fillna('')\n",
    "df.downloads = df.downloads.apply(clean_downloads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pubmed_id(authors):\n",
    "    base = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/'\n",
    "    esearch= 'esearch.fcgi?'\n",
    "    db= 'db=pubmed&'\n",
    "    field= 'field=author&'\n",
    "    term_prefix = 'term='\n",
    "    and_syntax = '+AND+'\n",
    "    term_suffix = '&'\n",
    "    api = 'api_key=56a5fd6220202c3f7c1c924f215c4188b708'\n",
    "    \n",
    "    if authors=='':\n",
    "        return \"No authors\"\n",
    "    authors = authors.lower()\n",
    "    authors = authors.split(',')\n",
    "    \n",
    "    if len(authors) > 2:\n",
    "        term = re.sub(' ','+',authors[0])+and_syntax+re.sub(' ','+',authors[1])+and_syntax+re.sub(' ','+',authors[2])\n",
    "    elif len(authors) > 1:\n",
    "        term = re.sub(' ','+',authors[0])+and_syntax+re.sub(' ','+',authors[1])\n",
    "    else:\n",
    "        term = re.sub(' ','+',authors[0])\n",
    "        \n",
    "    url = base+esearch+db+field+term_prefix+term+term_suffix+api\n",
    "    \n",
    "    response=requests.get(url)\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pmid(xml):\n",
    "    if xml==\"No authors\":\n",
    "        return [xml]\n",
    "    test_if_error =  re.search('error',xml[:9])\n",
    "    if (test_if_error!=None):\n",
    "        return [xml]\n",
    "    tmp = re.split('<Count>',xml)\n",
    "    tmp = re.split('</Count>',tmp[1])\n",
    "    count = int(tmp[0])\n",
    "    if count ==0:\n",
    "        return [count,\"\"]\n",
    "    else:\n",
    "        tmp = re.split('<IdList>',xml)\n",
    "        tmp = re.split('</IdList>',tmp[1])\n",
    "        tmp = re.split('</Id>',tmp[0])\n",
    "        tmp = map(lambda x: re.sub('<Id>','',x),tmp)\n",
    "        tmp = list(map(lambda x: re.sub('\\n','',x),tmp))\n",
    "        return [count,*tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain authors from the data frame and query Entrez for PMIDs\n",
    "author_list = list(df.author_names.fillna('').values)\n",
    "pmid_result = []\n",
    "for i in range(len(author_list)):\n",
    "    tmp = get_pubmed_id(author_list[i])\n",
    "    pmid_result.append(tmp)\n",
    "    time.sleep(0.2)\n",
    "    \n",
    "#Optionally write result to CSV\n",
    "#tmp = pd.Series(pmid_result)\n",
    "#tmp.to_csv('pmids.csv')\n",
    "\n",
    "#Parse raw PMID returns into count of hits, and PMID numbers. Add as new column to df\n",
    "parsed_pmid = list(map(parse_pmid,pmid_result))\n",
    "df['pmid']=pd.Series(parsed_pmid)\n",
    "\n",
    "#Subset the data on just results that have one hit for a PMID, meaning a one to one mapping of authors to PMID\n",
    "#Assign values to dataframe called df_subset\n",
    "subset_vec = []\n",
    "for i in range(len(df.pmid)):\n",
    "    if len(df.pmid[i])==3:\n",
    "        subset_vec.append(True)\n",
    "    else:\n",
    "        subset_vec.append(False)\n",
    "subset_indices = df.pmid[subset_vec].index\n",
    "df_subset = df.iloc[subset_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
